[Model](https://huggingface.co/TheBloke/CapybaraHermes-2.5-Mistral-7B-GGUF)

Steps to run model locally via llama-cpp-python python:
- Create venv and install server_requirements.txt
- MUST be saved in models/ directory
- Run server with this command: python -m llama_cpp.server --model models/capybarahermes-2.5-mistral-7b.Q4_K_M.gguf

